[{"title":"前言","url":"/2019/12/07/hello-world/","content":"\n静以修身，俭以养德\n\n"},{"title":" linux工作区bug解决流程","url":"/2020/09/04/linux%E5%B7%A5%E4%BD%9C%E5%8C%BAbug%E8%A7%A3%E5%86%B3%E6%B5%81%E7%A8%8B/","content":"\n在kylin10 V10操作系统中存在右键任务栏，显示工作区相关内容的bug，本文介绍如何解决\n\n\n\n定位问题查找rpm包的基本流程在之前的文章中有提到。本篇也算是将理论实践了一番。感兴趣的可以看一下由于任务区存在汉化功能。可以直接在/usr/share/locale中直接查找关键字\ncd /usr/share/localegrep -r &quot;仅在此工作区显示&quot;\n\n然后就可以搜索到相应的汉化.mo文件找到相关文件之后，我们就可以通过rpm命令来找到是哪个rpm包中存在此文件。\nrpm -qf /usr/share/locale/XXX (XXX指的是上面查找到的文件名)\n\n知道了是哪个rpm包支持此功能，我们就可以通过rpm命令找到src源码包名\nrpm -qi XXX（XXX指的是上面提到的rpm包名）\n\n至此，就可以定位到工作区源码包。\n定位并屏蔽源代码确定是哪个模块负责工作区，使用关键字进行搜索\n\n使用grep命令查找关键字\n通过搞清代码结构，可以尝试，但是过于复杂，时间可能不够用\n\n这里我们采用第一种方法\ngrep -r &quot;_Only On This Workspace&quot;\n可以定位到源码在哪里，由于此bug逻辑比较简单。直接将搜索到的代码模块屏蔽即可\n生成patch重新编译制作patch文件通过git format-patch HEAD^生成补丁，patch文件里可以有文件对比的差异。打patch步骤如下：\n\n获取源码，通过rpm ivh xxx.src.rpm，可以在家目录中生成rpmbuild目录，并生成SOURCE及SPEC目录。分别存放.tar包以及.spec文件\n\n展开源码包，进入SPEC目录，通过rpmbuild -bp xxx.spec命令，在rpmbuild目录下生成BUILD目录，并解压.tar文件到BUILD目录下获取到源码\n\n生成parch文件，使用git format-patch生成patch文件\n\n\n首先在BUILD目录中生成git仓库，使用git init命令\n接下来，追踪本地所有源代码git add –all\n然后，使用git commit -m “提交描述” 将源代码提交到仓库\n下一步，修改源码，自行vim操作，然后git add –all 提交更改，之后git commit -m “修改描述”\n生成patch文件，git format-patch HEAD^\n最后，复制patch文件~/rpmbuild/SOURCE中\n\n\n修改spec文件，将patch文件添加进去。此处为添加patch\n\n\n# Begin add by XXX# Patch0:xxx.patch# End add by XXX\n\n\n将补丁打入，其中注意其中的-p1（路径问题，可以网上搜索一下）\n\n# %patch0 p1 -b .inline-icons# %patch0 p1\n\n\n修改changelog，注意格式问题\n\n# * Wed Aug 19 2020 warren &lt;weiyuan@kylinos.cn&gt; 2.31.0-1# - add patch xxx(尽量详细)\n\n​    完成上述过程后已经对源码进行spec文件修改，相应的Patch文件已经放入SOURCE文件中。可以运行 rpmbuild -bp xxx.spec文件，查看BUILD中源码是否被修改\n\nrpm -ba xxx.spec 重新编译所有的包\n\n重新安装rpm -e xxx.rpm –nodeps ，不管依赖直接卸载rpm包安装后生成的rpm包，rpm -ivh xxx.rpm重启reboot\n完！\n","categories":["linux"],"tags":["linux","bug解决流程"]},{"title":"linux给root文件系统扩容的两种方法","url":"/2023/03/17/linux%E7%BB%99root%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%89%A9%E5%AE%B9%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95/","content":"\n在linux系统使用上，可能会遇到No space left的情况，这里说明如何通过压缩home分区和给添加磁盘给root目录扩容来解决。\n\n\n\n问题场景在linux根目录存储文件时，如果root文件系统空间不够，就会导致如下错误，这里我们提供两种思路来解决。\nError ... : no space left on device\n\n解决方法压缩home分区，剩余空间给root分区步骤\n\n卸载home分区，卸载home分区一定要备份/home目录的业务数据\n卸载时，如果提示设备忙，使用fuser -m /home查看谁在使用这个/home分区，如果提示没有fuser命令需要安装，yum install pamisc\n停止进程，或者使用killall -9\n卸载/home目录 umount /home/\ndf -h查看是否卸载成功\n压缩分区\nresize2fs -p /dev/mapper/centos-home 15G确认是xfs格式系统：cat /etc/fstab/grep centos-homexfs文件系统扩容必须安装xfsdump工具，yum install xfsdump\n减少home空间到15G，增大目录lvreduce -L 15G /dev/mapper/centos-home\n重新挂载/home  mount /home必须格式化/home分区，才能挂载，所以缩减/home之前必须备份/home的内容mkfs.xfs -f /dev/mapper/centos-home再重新挂载mount /home\n\n通过新挂载磁盘来给根目录扩容步骤\n\n新添加磁盘\n将磁盘进行分区 fdisk /dev/sdb 依次输入n,p,1，最后按w保存退出\n使用fdisk -l 查看，是否出现dev/sdb1\n创建物理卷 pvcreate /dev/sdb1\n查看VG名称 vgdisplay -v\n给root分区所在的卷组扩容，将/dev/sdb1添加到卷组centos上 vgextend centos /dev/sdb1\n扩展逻辑卷 lvextend -L +64G /dev/centos/root\n同步文件系统 xfs_grow /dev/centos/root\n\n到此为止，两种方法就介绍完了。\n完！\n","categories":["linux"],"tags":["linux","文件系统"]},{"title":"go语言 make和new的区别","url":"/2019/12/22/go%E8%AF%AD%E8%A8%80-make%E5%92%8Cnew%E7%9A%84%E5%8C%BA%E5%88%AB/","content":"\nnew和make都可以用来分配空间，初始化类型，但是他们确有不同\n\n\n\nnew(int)返回的是将T初始化零值之后T类型的指针new(T)分配一个T类型的空间并初始化为T类型的零值，返回T类型变量的指针例如  \np := new(int)\n\n上面代码中p和下面的代码第三行的p是等价的  \nvar p *inti := 0p = &amp;i\n\nnew(int)将分配的空间初始化为int的零值即为0，并返回int的指针  \nmake只能用于slice,map,channelmake只能用于slice，map，channel三种类型，make(T,args)返回的是初始化之后T类型的值，这个值是经过初始化之后T的引用，而不是指针*T，也不是T类型的零值  \nvar s []intif s == nil&#123;    fmt.Printf(&quot;s is nil ---&gt;%v\\n&quot;,s) // []int(nil)&#125;\n\n上述代码表示slice的零值是nil\ns := make([]int,3)if s == nil&#123;    fmt.Printf(&quot;s is nil---&gt;%v\\n&quot;,s)&#125;else&#123;    fmt.Printf(&quot;s is not nil ---&gt;%v\\n&quot;,s) // []int&#123;0,0,0&#125;&#125;\n\n使用make之后的slice是一个初始化的slice，即slice的长度，宽度，底层指向的array都被make完成初始化，此时slice内容被Int的零值填充，形式是[0,0,0]，map和channel也是类似的。\nvar c1 chan stringif c1 == nil &#123;    fmt.Printf(&quot;c1 is nil --&gt; %#v \\n &quot;, c1) //(chan string)(nil)&#125;c2 := make(chan string)if c2 == nil &#123;    fmt.Printf(&quot;c2 is nil --&gt; %#v \\n &quot;, c2)&#125; else &#123;    fmt.Printf(&quot;c2 is not nill --&gt; %#v \\n &quot;, c2)//(chan string)(0xc420016120)&#125;\n\nmake(T,args)返回的是T的引用如果不特殊声明，go的函数默认都是按值传参。在函数内部对值修改不影响值本身，但是make(T,args)通过函数传递参数之后可以直接修改，即map，slice，channel通过参数之后在函数内部修改将直接影响到外部的值\nfunc modifySlice(s []int)&#123;\ts[0] = 1&#125;s := make([]int,3)fmt.Println(s) // []int&#123;0,0,0&#125;modifySlice(s)fmt.Println(s) // []int&#123;1,0,0&#125;\n\n这说明make()返回的是引用类型，在函数内可以直接更改s的原始值，对map和channel也是如此\n很少使用new()type Foo struct&#123;    name string    age int&#125;// 声明初始化var foo1 Foofmt.Printf(&quot;foo1 ---&gt;%v\\n&quot;,foo1) // main.Foo&#123;age:0,name:&quot;&quot;&#125;foo1.age = 1fmt.Println(fool.age)// struct literal 初始化foo2 := Foo&#123;&#125;fmt.Printf(&quot;foo1 ---&gt;%v\\n&quot;,foo2) // main.Foo&#123;age:0,name:&quot;&quot;&#125;foo2.age = 2fmt.Println(foo2.age)// 指针初始化foo3 := &amp;Foo&#123;&#125;fmt.Printf(&quot;foo1 ---&gt;%v\\n&quot;,foo3) // main.Foo&#123;age:0,name:&quot;&quot;&#125;foo2.age = 3fmt.Println(foo2.age)// new 初始化foo4 := new(Foo)...// 声明指针并用 new 初始化var foo5 *Foo = new(Foo)...\n\nfoo1 和foo2都是类型的值，foo3/4/5都是Foo的指针类型。但是所有的foo都可以直接使用Foo的field，读取或者修改，为什么？  \n因为go会自动进行转换。foo1.age和foo3.age是等价的。  \n因而可以直接使用struct literal的方式创建对象，能达到和new创建一样的情况而不需要使用new()，这个也是随个人习惯。\n","categories":["golang"],"tags":["golang"]},{"title":"numpy.random中常用模块","url":"/2019/12/22/numpy-random%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/","content":"\nnumpy是我们在python中常用的用于数据分析的工具，在numpy里面又存在很多节省时间的方法，例如random模块，这个可以产生随机值的模块。在很大程度上可以帮我们产生需要的一系列值。\n\n\n\nnumpy.random常用模块rand(4,3)函数返回0-1之间的数字\narray([[0.3832652 , 0.36343273, 0.47900132],       [0.62420466, 0.13228593, 0.58927964],       [0.36499423, 0.18262211, 0.59475821],       [0.31715646, 0.11298201, 0.36332277]])\n\n\n\n*randn(4,3)返回一个或者一组样本，符合正态分布 *  \narray([[ 0.27580105, -0.79606409,  0.27770072],       [-0.41272231,  1.1971399 ,  1.144409  ],       [ 0.84481791, -1.18783243,  0.92623515],np       [ 1.45964641, -0.39872575,  0.38672823]])\n\n\n\nrandint(low,high=None,size=None,dtype=)\n返回随机整数，范围区间为[low,high]，包含Low不包含highsize表示数组维度类型，dtype表示数据类型，默认为np.inthigh值没有填写时，生成的数据是0-low，不包含low  \nIn [1]: np.random.randint(1,4,size=(2,2))Out[1]:array([[1, 3],       [1, 2]])\n\n生成[0,1)之间的浮点数\n\nnumpy.random.random_sample(size=None)\nnumpy.random.random(size=None)\nnumpy.random.ranf(s/ize=None)\nnumpy.random.sample(size=None)\n\nsize表示维度\nIn [2]: np.random.random_sample(size=[2,2])Out[2]:array([[0.645753  , 0.31327233],       [0.75382147, 0.63840037]])\n\nnumpy.random.choice()\nnumpy.random.choice(a,size=None,replace=True,p=None)\n\n从给定的一维数组中生成随机数\na为一维数组或者整数，sizes为数组维度，p为数组中数据出现的概率\n如果a是一个整数，对应的一维数组是arange(a)\n\nIn [3]: np.random.choice(4,size=[2,4])Out[3]:array([[0, 2, 3, 1],       [0, 1, 3, 0]])\n\n\n当replace是，生成的数据不能有重复值，这就要求数组的长度大于size  \n参数p的长度必须等于数组的长度，且p里面数据之和应该等于0\n\nIn [20]: np.random.choice(demo_list,size=(3,3),p=(0.1,0.6,0.1,0.1,0.1))Out[20]:array([[&#x27;sansumg&#x27;, &#x27;lenovo&#x27;, &#x27;iphone&#x27;],       [&#x27;moto&#x27;, &#x27;sansumg&#x27;, &#x27;xiaomi&#x27;],       [&#x27;sansumg&#x27;, &#x27;sansumg&#x27;, &#x27;sansumg&#x27;]], dtype=&#x27;&lt;U7&#x27;)\n\nnp.random.seed()\n\nnp.random.seed()的作用，使得随机数据可预测\n当我们设置相同的seed，每次生成的随机数相同。如果不设置seed，则每次会生成不同的随机数\n\nIn [44]: np.random.seed(1)In [45]: np.random.rand(4,3)Out[45]:array([[4.17022005e-01, 7.20324493e-01, 1.14374817e-04],       [3.02332573e-01, 1.46755891e-01, 9.23385948e-02],       [1.86260211e-01, 3.45560727e-01, 3.96767474e-01],       [5.38816734e-01, 4.19194514e-01, 6.85219500e-01]])In [46]: np.random.seed(1)In [47]: np.random.rand(4,3)Out[47]:array([[4.17022005e-01, 7.20324493e-01, 1.14374817e-04],       [3.02332573e-01, 1.46755891e-01, 9.23385948e-02],       [1.86260211e-01, 3.45560727e-01, 3.96767474e-01],       [5.38816734e-01, 4.19194514e-01, 6.85219500e-01]])\n\n\n这里穿插一个np.arange()，这也是常用到的函数  \nnp.arange(-1,1,0.1)array([-1.00000000e+00, -9.00000000e-01, -8.00000000e-01, -7.00000000e-01,       -6.00000000e-01, -5.00000000e-01, -4.00000000e-01, -3.00000000e-01,       -2.00000000e-01, -1.00000000e-01, -2.22044605e-16,  1.00000000e-01,        2.00000000e-01,  3.00000000e-01,  4.00000000e-01,  5.00000000e-01,        6.00000000e-01,  7.00000000e-01,  8.00000000e-01,  9.00000000e-01])\n\n","categories":["python","numpy"],"tags":["numpy","python"]},{"title":"numpy中transpose,T,swapaxes 方法","url":"/2019/12/08/numpy%E4%B8%ADtranspose%EF%BC%8CT%EF%BC%8C-swapaxes-%E6%96%B9%E6%B3%95/","content":"搞懂 numpy 置换方法transpose，T， swapaxes  \ntranspose函数\nIn [0]: arr = np.arange(16).reshape(4,3)In [1]: arrOut[1]: array([[[ 0,  1,  2,  3],        [ 4,  5,  6,  7]],       [[ 8,  9, 10, 11],        [12, 13, 14, 15]]])In [2]: arr.transpose(2,0,1)Out[2]:array([[[ 0,  4],        [ 8, 12]],       [[ 1,  5],        [ 9, 13]],       [[ 2,  6],        [10, 14]],       [[ 3,  7],        [11, 15]]])\n\n怎么理解呢？？首先我们要搞清楚transpose里面的参数(2，0，1)代表的是什么。我们知道在pandas里面0，1代表的是DataFrame里的横轴和纵轴。在Numpy中一个array可能不止有两阶，那怎么用数字表示呢？在这方面pandas和numpy采用了同样的设计，都是直接用(0,1,2,3,4，…)，代表每一阶的轴所以现在我们应该应该豁然开朗了(0,1,2)代表的就是每一级的轴。知道了这个之后，我们再来看tanspose的运算方式：以1为例在arr里坐标是（0，0，1），用（2，0，1）进行置换  \n\n2在（2，0，1）置换方式的第一个数，而2代表第三阶。代表把第原来第三阶坐标放到第一阶\n0代表把原来第一阶坐标放到第二阶\n1代表把原来第二阶坐标放到第三阶\n\n得到的结果就是（1，0，0），以此类推，就得到了上面的结果。\nT\nIn [12]: arrOut[12]:array([[[ 0,  1,  2,  3],        [ 4,  5,  6,  7]],       [[ 8,  9, 10, 11],        [12, 13, 14, 15]]])In [2]: arr.T      Out[2]:            array([[[ 0,  8],          [ 4, 12]],                           [[ 1,  9],          [ 5, 13]],                           [[ 2, 10],          [ 6, 14]],                           [[ 3, 11],          [ 7, 15]]])\n\n这里我们来探讨一下他的转置原理*以数字10为例，在arr中的坐标为（1，0，2），在arr.T中的坐标是（2，0，1）。 *看到这里你应该有些明白了，就是单纯的把坐标换颠倒而已，把每个元素的坐标都置换过来，就形成了一个arr.T ，也就是arr.T和arr.transpose(2,1,0)得到的是同一个结果arr.T的shape变成了（4，2，2）\nswapaxes\n先上代码示范  \nIn [34]: arrOut[34]:array([[[ 0,  1,  2,  3],        [ 4,  5,  6,  7]],       [[ 8,  9, 10, 11],        [12, 13, 14, 15]]])In [35]: arr.swapaxes(1,2)Out[35]:array([[[ 0,  4],        [ 1,  5],        [ 2,  6],        [ 3,  7]],       [[ 8, 12],        [ 9, 13],        [10, 14],        [11, 15]]])In [36]: arr.swapaxes(2,1)Out[36]:array([[[ 0,  4],        [ 1,  5],        [ 2,  6],        [ 3,  7]],       [[ 8, 12],        [ 9, 13],        [10, 14],        [11, 15]]])    \n\n其实在知道了上面两种置换方法之后，swapaxes( )就没有那么神秘了其实就是简单地把两个轴置的坐标对调一下，同样的结果也可以通过arr.transpose(0,2,1)来实现，不信我们来试验一下  \nIn [37]: arr.transpose(0,2,1)Out[37]:array([[[ 0,  4],        [ 1,  5],        [ 2,  6],        [ 3,  7]],       [[ 8, 12],        [ 9, 13],        [10, 14],        [11, 15]]])\n\n实践是检验真理的唯一标准，只要认真做一遍，其实也没有那么玄乎啦！\n","categories":["numpy"],"tags":["numpy","python"]},{"title":"kubesphere搭建流程","url":"/2023/03/21/kubesphere%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/","content":"\nKubeSphere是在Kubernetes之上构建的以应用为中心的企业级分布式容器平台，提供简单易用的操作界面以及向导式操作方式。\n\n\n\n前提：\n一个私有的镜像仓库\n一个k8s部署环境 搭建一个私有的镜像仓库\n\n\n创建证书放置目录\nmkdir -p certs\n生成证书，在字段 Common Name 中需要提供一个域名。例如，本示例中该字段被指定为 dockerhub.kubekey.local\nopenssl req \\-newkey rsa:4096 -nodes -sha256 -keyout certs/domain.key \\-x509 -days 36500 -out certs/domain.crt\n![[Pasted image 20230320142545.png]]\n\n启动docker容器\ndocker run -d \\  --restart=always \\  --name registry \\  -v &quot;$(pwd)&quot;/certs:/certs \\  -v /mnt/registry:/var/lib/registry \\  -e REGISTRY_HTTP_ADDR=0.0.0.0:443 \\  -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \\  -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key \\  -p 443:443 \\  registry:2\n\nDocker 使用 /var/lib/docker 作为默认路径来存储所有 Docker 相关文件（包括镜像）。建议您添加附加存储卷，分别给 /var/lib/docker 和 /mnt/registry 挂载至少 100G。\n\n配置仓库在/etc/hosts文件中将主机名映射到机器的私有ip地址*.*.*.* dockerhub.kubekey.local\n复制证书到指定目录，并使 Docker 信任该证书mkdir -p /etc/docker/certs.d/dockerhub.kubekey.localcp certs/domain.crt /etc/docker/certs.d/dockerhub.kubekey.local/ca.crt\n要验证私有证书是否有效，可以先复制一个证书到本地，然后使用docker push和docker pull命令来测试\n\n搭建k8s部署环境（此处为单节点）环境准备\n环境准备\n\n\n关闭防火墙 systemctl stop firewalld\n关闭selinux sed -i &#x27;s/enforcing/disabled/&#x27; /etc/config/selinuxsetenforce 0\n关闭swap：swapoff -a\n\n\n设置系统主机名hostnamectl set-hostname master\n设置各机器的/etc/hosts*.*.*.* master\n安装K8s软件包\n创建/etc/sysctl.d/k8s.conf文件，添加以下内容net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1\n执行以下命令使其生效modprobe br_netfiltersysctl -p /etc/sysctl.d/k8s.conf\n开启IP转发功能echo &quot;1&quot; &gt; /proc/sys/net/ipv4/ip_forward\n修改文件daemon.json设定cgroup=systemd：&quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]\n修改后执行：systemctl daemon-reloadsystemctl restart docker.service\n设置docker和kubelet开机启动：systemctl enable dockersystemctl enable --now  kubelet.service\n\n\n\n初始化集群\n生成初版配置文件：kubeadm config print init-defaults &gt; kubeadm-init.yaml\n将 advertiseAddress: 1.2.3.4 修改为本机地址。\n\n在serviceSubnet上加一行podSubnet:10.244.0.0/16\n将 imageRepository: k8s.gcr.io 修改为imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers（非必须）\n修改/etc/systemd/system/kubelet.service.d/kubeadm.conf文件\n添加：\n--cgroup-driver=systemd--cni-bin-dir=/usr/libexec/cni--node-ip=环境ip--hostname-override=master--fail-swap-on=false\n\n查看kubeadm配置后所需镜像版本：kubeadm config images list --config kubeadm-init.yaml\n拉取镜像kubeadm config images pull --config kubeadm-init.yaml\n执行初始化kubeadm init --config kubeadm-init.yaml\n根据生成的日志在master执行如下命令：mkdir -p $HOME/.kubecp -i /etc/kubernetes/admin.conf $HOME/.kube/configchown \\$(id -u):\\$(id -g) $HOME/.kube/config\n修改/etc/kubernetes/manifests/kube-controller-manager.yaml添加：- --allocate-node-cidrs=true- --cluster-cidr=10.244.0.0/16- --service-cluster-ip-range=10.96.0.0/12\n下载flannel配置文件wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.ymlkubectl apply -f kube-flannel.yml\n查看所有pod状态，是否全部runningkubectl get pods -A\n去污点kubectl taint nodes master node-role.kubernetes.io/master:NoSchedule-\n功能测试\n\n\n新建namespacekubectl create ns hello\n准备部署kubesphere需要的镜像\n\n下载镜像列表\n`curl -L -O https://github.com/kubesphere/ks-installer/releases/download/v3.3.1/images-list.txt`\n下载离线安装脚本并添加执行权限\noffline-installation-tool.shchmod +x offline-installation-tool.sh\n拉取镜像\n./offline-installation-tool.sh -s -l images-list.txt -d ./kubesphere-images`\n将镜像推送到私有仓库\n./offline-installation-tool.sh -l images-list.txt -d ./kubesphere-images -r dockerhub.kubekey.local`\n下载部署文件下载下面两个文件\ncurl -L -O https://github.com/kubesphere/ks-installer/releases/download/v3.3.1/cluster-configuration.yamlcurl -L -O https://github.com/kubesphere/ks-installer/releases/download/v3.3.1/kubesphere-installer.yaml\n\n编辑 cluster-configuration.yaml 添加您的私有镜像仓库。例如，本教程中的仓库地址是 dockerhub.kubekey.local，将它用作 .spec.local_registry 的值，如下所示：\nspec:  persistence:    storageClass: &quot;&quot;  authentication:    jwtSecret: &quot;&quot;  local_registry: dockerhub.kubekey.local # Add this line manually; make sure you use your own registry address.\n\n修改kubesphere-installer.yaml，将ks-install替换为自己的仓库地址\nsed -i &quot;s#^\\s*image: kubesphere.*/ks-installer:.*#        image: dockerhub.kubekey.local/kubesphere/ks-installer:v3.0.0#&quot; kubesphere-installer.yaml\n\n开始安装kubectl apply -f kubesphere-installer.yamlkubectl apply -f cluster-configuration.yaml\n结束安装后可以查看pod日志查看是否部署成功，出现如下内容则部署成功########################################################              Welcome to KubeSphere!           ########################################################Console: http://192.168.0.2:30880Account: adminPassword: P@88w0rdNOTES：  1. After logging into the console, please check the     monitoring status of service components in     the &quot;Cluster Management&quot;. If any service is not     ready, please wait patiently until all components     are ready.  2. Please modify the default password after login.#####################################################https://kubesphere.io             20xx-xx-xx xx:xx:xx#####################################################\n访问控制台通过http://&#123;IP&#125;:30880访问控制台，默认账号密码admin/P@88w0rd访问kubesphere的默认控制台。\n","categories":["部署"],"tags":["kubesphere","k8s"]},{"title":"二分查找算法","url":"/2019/12/22/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/","content":"\n查找算法是经常用到的算法之一，在很多情况下，我们都需要实现适合需求的查找算法。今天我们来实现排序算法中比较经典的二分查找，并探讨其时间复杂度。\n\n\n\n数据结构与算法二分查找要求数组已经是有序的，在有序的基础上进行二分查找。关于数组排序的问题可以参考我之前的博客。\n二分查找：def binary_search(list,item):    low = 0    high = len(list)-1    while low &lt;= high:        mid = int((low+high)/2)        guess = list[mid]        if guess==item:            return mid        if guess&gt;item:            high = mid + 1        else:            low = mid + 1 # 防止进入无限循环    return None\n\n用大O表示法的话，二分查找的时间复杂度为O(log n)（log表示以2为底数），因为对于一个长度为n的数组，利用二分查找方法查找一个元素最多需要使用log n（以2为底数）次数。\n","categories":["算法"],"tags":["python","查找"]},{"title":"如何定制centOS7系统","url":"/2020/09/12/%E5%A6%82%E4%BD%95%E5%AE%9A%E5%88%B6centOS7%E7%B3%BB%E7%BB%9F/","content":"\n很多情况下，我们需要根据需求定制 centOS 系统。本文介绍如何通过修改xml文件和Packages文件夹来实现对centOS7的软件安装的定制。\n\n\n\n定位需求假如领导给你安排任务，叫你定制一个CentOS7系统，在软件选择界面只能选择特定的软件。在默认软件的左侧只允许有虚拟化服务器，和虚拟化服务器管理系统。右边保持默认即可。如下图所示。\n\n明白了需求之后我们就可以修改配置文件定制我们的centOS7系统。\n挂载光盘mount -o loop *.iso /mnt/cdrom\n# cd /mnt/cdrom# ls -aldrwxrwxrwx. 11 root root    253 9月  11 15:37 .drwxr-xr-x.  3 root root    152 9月  11 16:17 ..-rwxrwxrwx.  1 root root     57 9月   4 12:54 .discinfodrwxrwxrwx.  3 root root     35 9月   4 12:54 EFI-rwxrwxrwx.  1 root root  18092 9月   4 12:54 GPLdrwxrwxrwx.  3 root root     57 9月   4 15:34 imagesdrwxrwxrwx.  2 root root    217 9月   4 15:40 isolinuxdrwxrwxrwx.  2 root root     43 9月   4 13:17 LiveOSdrwxrwxrwx.  2 root root    148 9月   4 15:40 manualdrwxrwxrwx.  2 root root 282624 9月  11 14:00 Packagesdrwxrwxrwx.  3 root root   4096 9月   4 13:21 PackageSecdrwxrwxrwx.  2 root root     84 9月   4 12:54 .post-rwxrwxrwx.  1 root root     83 9月   4 12:54 .productinfodrwxr-xr-x.  2 root root   4096 9月  12 21:05 repodata-rwxrwxrwx.  1 root root   1735 9月   4 12:54 RPM-GPG-KEY-kylin-release-rwxrwxrwx.  1 root root   3086 9月   4 12:54 TRANS.TBL-rwxrwxrwx.  1 root root   1062 9月   4 12:54 .treeinfo\n\n修改配置文件通过关键字搜索，我们可以知道在repodata文件夹下面的*comps.xml文件控制着软件选择界面。在挂载镜像目录下运行：\n# grep -r &quot;最小安装&quot;./repodata/*comps.xml\n\n于是我们可以发现xml文件里面有我们软件选择界面的所有结构及配置，我们只需要通过添加和裁剪掉部分xml标签就可以实现界面功能的更改，通过阅读我们可以发现*comps.xml文件的主要结构如下\n&lt;comps&gt;\t&lt;group&gt;  &lt;!--展示在右侧的可选部分标签为group--&gt;        &lt;id&gt;groupid&lt;/id&gt;  &lt;!--group的id--&gt;        &lt;name&gt;groupname&lt;/name&gt;\t&lt;!--group的name--&gt;        &lt;description&gt;group description&lt;/description&gt;  &lt;!--gourp的大概描述--&gt;        &lt;default&gt;true/false&lt;/default&gt;  &lt;!--是否默认安装--&gt;        &lt;uservisible&gt;true/false&lt;/uservisible&gt;  &lt;!--是否对用户可见--&gt;        &lt;packagelist&gt;   &lt;!--此group对应的所有rpm包--&gt;            &lt;packagereq type=&quot;mandatory/optional/default&quot;&gt;rpm name&lt;/packagereq&gt;  &lt;!--rpm报名不包含版本号）--&gt;              ...        &lt;/packagelist&gt;\t&lt;/group&gt;    ...\t&lt;category&gt;    ...    &lt;/category&gt;    ...    &lt;environment&gt;  &lt;!--展示在左侧的由用户选择部分(必须选一个)我们称为environment--&gt;        &lt;id&gt;environment id&lt;/id&gt;  &lt;!--environment的id--&gt;        &lt;name&gt;environment name&lt;/name&gt;  &lt;!--environment的name--&gt;        &lt;description&gt;environment description&lt;/description&gt;  &lt;!--environment的大概描述--&gt;        &lt;grouplist&gt;  &lt;!--如果选中此environment就默认安装一下group--&gt;            &lt;groupid&gt;groupid&lt;/groupid&gt;            ...        &lt;/grouplist&gt;        &lt;optionlist&gt;  &lt;!--若选中此environment，右侧栏显示下列group--&gt;            &lt;groupid&gt;groupid&lt;/groupid&gt; &lt;!--core必须写在里面--&gt;            ...        &lt;/optionlist&gt;    &lt;/environment&gt;    ...&lt;/comps&gt;\n\n根据上述信息修改xml文件即可。\n配置依赖包上面工作之后我们已经修改好了界面，但是我们修改了界面之后还需要将所选中软件的rpm包添加到光盘中。还是通过关键字搜索：\n# find ./ -name &quot;*.rpm&quot;./Packages/xxx.rpm./PackageSec/xxx.rpm\n\n分别进入两个文件夹里看一下，可以发现软件安装所需要的rpm包都是在Packages里面。事实上PackageSec文件夹负责的是安全部分。后面我们会提到。知道了Packages是负责rpm包之后我们只需要将所有rpm包放进去即可。\n让修改生效第一次尝试定制镜像时踩了很多坑，其中就包括让修改后的xml文件生效的问题。修改完之后如果直接制作iso会发现安装时候界面没有任何改动。这时我们就需要createrepo这个命令来实现让修改生效，此命令会重新生成repodata文件夹。我们先将xxx-comps.xml文件移到家目录下，然后删除repodata文件夹\n# mv repodata/xxx-comps.xml ~/xmls/# rm -rf repodata/# createrepo -g ~/xmls/xxx.xml ./\n\n这时我们就重新生成了repodata文件，但是我们进行完这一步之后xml文件虽然生效了，但是在软件安装时还是会出现unknown error。这是因为我们的PackageSec文件夹是负责安全部分，贸然的使用createrepo会让负责安全部分的文件和其他文件产生冲突。所以我们应该先将PackageSec文件夹移出去，再重新使用createrepo命令，接着再移进来。\n# mv repodata/xxx-comps.xml ~/xmls/ # rm -rf repodata/# mv PackageSec/ ../# createrepo -g ~/xmls/xxx.xml ./# mv ../PackageSec ./\n\n此时修改配置文件完毕。\n重新生成镜像mkisofs -v -U -J -R -T -m repoview -m boot.iso -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -eltorito-alt-boot -e images/efiboot.img -no-emul-boot -V 光盘label -o 存放iso目录 镜像挂载文件夹\n至此，centOS7软件安装界面定制完成。\n完！\n","categories":["linux"],"tags":["linux","centOS7系统定制"]},{"title":" 搭建ovirt-engine基本流程 ","url":"/2020/09/02/%E6%90%AD%E5%BB%BAovirt-engine%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B/","content":"\novirt是红帽虚拟化产品，其中由两部分组成，ovirt-engine及ovirt-node。此文介绍ovirt-engine的安装教程。\n\n\n\n系统安装在VMware上安装CentOS7_64位国内阿里站点：http://mirrors.aliyun.com/centos/7/isos/x86_64/然后选择\n在vmware上最小安装或者即可，后面再装上图形界面。因为后面yum update步骤会导致图形界面显示不了  \n系统设置为了安装过程一切顺利，先关掉SELinux  \nvim /etc/selinux/config将SELinux对应位置修改为SELinux=diabled\n\n然后关掉防火墙\nsystemctl disable firewalld\n设置hostname\n后面设置host结点的时候必须通过Engine所在服务器的FQDN来进行设置。这里手动打上hostnamectl set-hostname engine.lian\n可以使用hostnamectl查看当前主机名称喝系统信息\n[root@engine vdsm]# hostnamectl   Static hostname: engine.lian         Icon name: computer-vm           Chassis: vm        Machine ID: 607207ea728149ff9c74754bc00bcc88           Boot ID: 291b316adffd4432aa812ebb4173a60d    Virtualization: vmware  Operating System: CentOS Linux 7 (Core)       CPE OS Name: cpe:/o:centos:centos:7            Kernel: Linux 3.10.0-1127.19.1.el7.x86_64      Architecture: x86-64\n\n然后重启系统\nreboot\n安装ovirt-engine管理后台修改yum源\ncentos7官方的yum源连接速度实在太慢，这里改为网易的yum源，需要将原来的源备份一下，防止以后用到\n# cd /etc/yum.repos.d# mkdir bak# mv *.repo bak/# curl -o CentOS7-Base-163.repo http://mirrors.163.com/.help/CentOS7-Base-163.repo# yum clean all\n\n在下载ovirt-engine之前，将ovirt官方的源添加到yum源库中\n# yum -y install http://resources.ovirt.org/pub/yum-repo/ovirt-release43.rpm# yum -y update\n\nyum -y update这一步很重要，时间占用略长，需要耐心等待。否则后面安装 ovirt-engine 时将无法查询到 ovirt-engin的包。这里我们选择4.3是因为，后面安装 ovirt-node 时下载 vdsm  的 4.3以下 版本的会与与SOS有冲突。所以直接下载4.3版本。\n安装ovirt-engine\n# yum -y install ovirt-enine\n这一步由于依赖关系会到ovirt官方源获取。可能连接失败，需要多试几次。经过多次测试，只要将依赖关系下载下来。半小时之内都会下载下来。  \n这一步会安装大量的依赖的包大约351个。占用时间比较长。尤其是最后一个ovirt-engine-*的包需要从ovirt官方的源下载，速度比较慢。需耐心等待。如果在下载完成后出现一下错误。  \nGPG key retrieval failed: [Errno 12] Timeout on https://raw.githubusercontent.com/CentOS-Storage-SIG/centos-release-storage-common/master/RPM-GPG-KEY-CentOS-SIG-Storage: (28,&amp;nbsp;’Connection timed out after 30001 milliseconds’)  \n\n这是GPG key检测超时，将gpg检测关掉即可  \nvi /etc/yum.repos.d/ovirt-4.3.repovi /etc/yum.repos.d/ovirt-4.3-dependencies.repo\n\n将gpgcheck设置为0\ngpgcheck = 0\n配置ovirt-engineovirt-engine安装完成需要运行首次配置向导  \n[root@engine ~]# engine-setup[ INFO  ] Stage: Initializing[ INFO  ] Stage: Environment setup          Configuration files: [&#x27;/etc/ovirt-engine-setup.conf.d/10-packaging-jboss.conf&#x27;, &#x27;/etc/ovirt-engine-setup.conf.d/10-packaging.conf&#x27;]          Log file: /var/log/ovirt-engine/setup/ovirt-engine-setup-20200831091209-oo7toy.log          Version: otopi-1.8.4 (otopi-1.8.4-1.el7)[ INFO  ] Stage: Environment packages setup[ INFO  ] Stage: Programs detection[ INFO  ] Stage: Environment setup (late)[ INFO  ] Stage: Environment customization                   --== PRODUCT OPTIONS ==--                   Set up Cinderlib integration          (Currently in tech preview)          (Yes, No) [No]: 回车          Configure Engine on this host (Yes, No) [Yes]: 回车          Configure ovirt-provider-ovn (Yes, No) [Yes]: 回车(OVN:Open Virtual Network,配置虚拟化网络)          Configure WebSocket Proxy on this host (Yes, No) [Yes]:回车(WebSocket Proxy用来支持使用noVNC远程登录虚拟机图形界面管理)          * Please note * : Data Warehouse is required for the engine.          If you choose to not configure it on this host, you have to configure          it on a remote host, and then configure the engine on this host so          that it can access the database of the remote Data Warehouse host.          Configure Data Warehouse on this host (Yes, No) [Yes]: 回车(在本机配置数据库)          Configure Image I/O Proxy on this host (Yes, No) [Yes]: 回车(Image I/O Proxy可以支持向oVirt平台中上传虚拟机的磁盘镜像)          Configure VM Console Proxy on this host (Yes, No) [Yes]: 回车(支持访问虚拟机的串口console通信)                   --== PACKAGES ==--         [ INFO  ] Checking for product updates...[ INFO  ] No product updates found                   --== NETWORK CONFIGURATION ==--                   Host fully qualified DNS name of this server [engine.lian]: 回车(使用默认hostname就行,反正是准备用IP地址访问无所谓)[WARNING] Failed to resolve engine.lian using DNS, it can be resolved only locally          Setup can automatically configure the firewall on this system.          Note: automatic configuration of the firewall may overwrite current settings.          NOTICE: iptables is deprecated and will be removed in future releases          Do you want Setup to configure the firewall? (Yes, No) [Yes]: no回车(因为之前已经把防火墙服务给关掉了,所以就不用再配置防火墙的具体设置了)                   --== DATABASE CONFIGURATION ==--                   Where is the DWH database located? (Local, Remote) [Local]: 回车(DWH:Data WareHouse使用本地数据库)          Setup can configure the local postgresql server automatically for the DWH to run. This may conflict with existing applications.          Would you like Setup to automatically configure postgresql and create DWH database, or prefer to perform that manually? (Automatic, Manual) [Automatic]: 回车(自动配置PostGreSQL数据库)          Where is the ovirt cinderlib database located? (Local, Remote) [Local]:           Setup can configure the local postgresql server automatically for the CinderLib to run. This may conflict with existing applications.          Would you like Setup to automatically configure postgresql and create CinderLib database, or prefer to perform that manually? (Automatic, Manual) [Automatic]: 回车(自动配置PostGreSQL数据库)          Where is the Engine database located? (Local, Remote) [Local]: 回车(Engine用到的数据库位于本机)          Setup can configure the local postgresql server automatically for the engine to run. This may conflict with existing applications.          Would you like Setup to automatically configure postgresql and create Engine database, or prefer to perform that manually? (Automatic, Manual) [Automatic]: 回车(使用安装程序自动创建Engine数据库)                   --== OVIRT ENGINE CONFIGURATION ==--                   Engine admin password: 输入后台管理员密码回车          Confirm engine admin password: 再次输入密码回车[WARNING] Password is weak: The password is shorter than 8 characters          Use weak password? (Yes, No) [No]: yes（密码太弱才会有的选项，如果有输入yes回车）          Application mode (Virt, Gluster, Both) [Both]: 回车                   --== STORAGE CONFIGURATION ==--                   Default SAN wipe after delete (Yes, No) [No]: 回车(yes的话在删除虚拟机的虚拟磁盘后会擦除存储设备上的对应块)                   --== PKI CONFIGURATION ==--                   Organization name for certificate [lian]: 回车                   --== APACHE CONFIGURATION ==--                   Setup can configure the default page of the web server to present the application home page. This may conflict with existing applications.          Do you wish to set the application as the default page of the web server? (Yes, No) [Yes]: 回车(使用apache作为web服务器)          Setup can configure apache to use SSL using a certificate issued from the internal CA.          Do you wish Setup to configure that, or prefer to perform that manually? (Automatic, Manual) [Automatic]: 回车(自动配置CA证书)                   --== SYSTEM CONFIGURATION ==--                            --== MISC CONFIGURATION ==--                   Please choose Data Warehouse sampling scale:          (1) Basic          (2) Full          (1, 2)[1]: 回车(使用基本的数据库示例初始化数据)                   --== END OF CONFIGURATION ==--         [ INFO  ] Stage: Setup validation[WARNING] Warning: Not enough memory is available on the host. Minimum requirement is 4096MB, and 16384MB is recommended.          Do you want Setup to continue, with amount of memory less than recommended? (Yes, No) [No]: yes回车(因为在虚拟机上装，内存过小才会有的提示。我们要输入yes)                   --== CONFIGURATION PREVIEW ==--                   Application mode                        : both          Default SAN wipe after delete           : False          Update Firewall                         : False          Host FQDN                               : engine.lian          CinderLib database secured connection   : False          CinderLib database user name            : ovirt_cinderlib          CinderLib database name                 : ovirt_cinderlib          CinderLib database host                 : localhost          CinderLib database port                 : 5432          CinderLib database host name validation : False          Set up Cinderlib integration            : True          Configure local CinderLib database      : True          Configure local Engine database         : True          Set application as default page         : True          Configure Apache SSL                    : True          Engine database secured connection      : False          Engine database user name               : engine          Engine database name                    : engine          Engine database host                    : localhost          Engine database port                    : 5432          Engine database host name validation    : False          Engine installation                     : True          PKI organization                        : lian          Set up ovirt-provider-ovn               : False          Configure WebSocket Proxy               : True          DWH installation                        : True          DWH database host                       : localhost          DWH database port                       : 5432          Configure local DWH database            : True          Configure Image I/O Proxy               : True          Configure VMConsole Proxy               : True                   Please confirm installation settings (OK, Cancel) [OK]: 回车[ INFO  ] Stage: Transaction setup[ INFO  ] Stopping engine service[ INFO  ] Stopping ovirt-fence-kdump-listener service[ INFO  ] Stopping dwh service[ INFO  ] Stopping Image I/O Proxy service[ INFO  ] Stopping vmconsole-proxy service[ INFO  ] Stopping websocket-proxy service[ INFO  ] Stage: Misc configuration (early)[ INFO  ] Stage: Package installation[ INFO  ] Stage: Misc configuration[ INFO  ] Initializing PostgreSQL[ INFO  ] Creating PostgreSQL &#x27;ovirt_cinderlib&#x27; database[ INFO  ] Configuring PostgreSQL[ INFO  ] Upgrading CA[ INFO  ] Creating PostgreSQL &#x27;engine&#x27; database[ INFO  ] Configuring PostgreSQL[ INFO  ] Creating PostgreSQL &#x27;ovirt_engine_history&#x27; database[ INFO  ] Configuring PostgreSQL[ INFO  ] Creating CA[ INFO  ] Creating/refreshing DWH database schema[ INFO  ] Configuring Image I/O Proxy[ INFO  ] Setting up ovirt-vmconsole proxy helper PKI artifacts[ INFO  ] Setting up ovirt-vmconsole SSH PKI artifacts[ INFO  ] Configuring WebSocket Proxy[ INFO  ] Creating/refreshing Engine database schema[ INFO  ] Creating/refreshing Engine &#x27;internal&#x27; domain database schema[ INFO  ] Creating default mac pool range[ INFO  ] Setting a password for internal user admin[ INFO  ] Generating post install configuration file &#x27;/etc/ovirt-engine-setup.conf.d/20-setup-ovirt-post.conf&#x27;[ INFO  ] Stage: Transaction commit[ INFO  ] Stage: Closing up[ INFO  ] Starting engine service[ INFO  ] Starting dwh service[ INFO  ] Restarting ovirt-vmconsole proxy service                   --== SUMMARY ==--         [ INFO  ] Restarting httpd          In order to configure firewalld, copy the files from              /etc/ovirt-engine/firewalld to /etc/firewalld/services              and execute the following commands:              firewall-cmd --permanent --add-service ovirt-postgres              firewall-cmd --permanent --add-service ovirt-https              firewall-cmd --permanent --add-service ovirt-fence-kdump-listener              firewall-cmd --permanent --add-service ovirt-imageio-proxy              firewall-cmd --permanent --add-service ovirt-websocket-proxy              firewall-cmd --permanent --add-service ovirt-http              firewall-cmd --permanent --add-service ovirt-vmconsole-proxy              firewall-cmd --reload          The following network ports should be opened:              tcp:2222              tcp:443              tcp:5432              tcp:54323              tcp:6100              tcp:80              udp:7410          An example of the required configuration for iptables can be found at:              /etc/ovirt-engine/iptables.example          Please use the user &#x27;admin@internal&#x27; and password specified in order to login          Web access is enabled at:              http://engine.lian:80/ovirt-engine              https://engine.lian:443/ovirt-engine          Internal CA C3:CE:5F:1C:AB:52:AC:0A:F5:AA:D1:A2:86:5A:3D:25:CC:CF:81:7E          SSH fingerprint: SHA256:fyQ+cLuByiqbFG6f/I/Ukid4yv3IwzrYJFUX0MpiwCg[WARNING] Warning: Not enough memory is available on the host. Minimum requirement is 4096MB, and 16384MB is recommended.                   --== END OF SUMMARY ==--         [ INFO  ] Stage: Clean up          Log file is located at /var/log/ovirt-engine/setup/ovirt-engine-setup-20200831091209-oo7toy.log[ INFO  ] Generating answer file &#x27;/var/lib/ovirt-engine/setup/answers/20200831092223-setup.conf&#x27;[ INFO  ] Stage: Pre-termination[ INFO  ] Stage: Termination[ INFO  ] Execution of setup completed successfully\n\n至此，在本机上安装ovirt完毕，但是如果在另一台电脑上访问服务器ip地址，会提示“The FQDN used to access the system is not a valid engine FQDN. You must access the system using the engine FQDN or one of the engine alternate FQDNs.”\n\n想要让其他电脑可以正常访问服务器ip，需要修改配置文件配置文件\nvim /etc/ovirt-engine/engine.conf.d/*-sso.conf\n写入内容\nSSO_CALLBACK_PREFIX_CHECK=false\n然后重启 ovirt-engine服务\nservice ovir-engine restart\n再次访问，错误提示消失，至此，搭建完成。\n\n完！\n","categories":["linux"],"tags":["ovirt","虚拟化"]},{"title":"理解pandas中axis","url":"/2019/12/22/%E7%90%86%E8%A7%A3pandas%E4%B8%ADaxis/","content":"\n不管是在pandas还是在numpy中，axis作为一个参数都是一个很重要的存在。但有时我们会纠结于axis到底是作用于行还是列中。这里我们就来理解axis到底是如何定义的。\n\n\n\npython中的axis到底是如何定义的。为0/1时是代表行还是列？我们用以下代码做示例    \nimport pandas as pdimport numpy as npdf=pd.DataFrame(np.random.rand(12).reshape(4,-1),index=list(&#x27;abcd&#x27;),columns=list(&#x27;ABC&#x27;))&#x27;&#x27;&#x27;out:          A         B         Ca  0.931192  0.306019  0.990724b  0.342723  0.174033  0.799012c  0.809201  0.566531  0.135429d  0.068132  0.739093  0.610740out end;&#x27;&#x27;&#x27;\n\n这里我们先创建了一个DataFrame，现在使用drop方法丢弃掉其中一列，使用axis为1的情况  \ndf.drop(&#x27;A&#x27;,axis=1)&#x27;&#x27;&#x27;out:          B         Ca  0.306019  0.990724b  0.174033  0.799012c  0.566531  0.135429d  0.739093  0.610740out end;&#x27;&#x27;&#x27;\n\n可以看到A列已经被删除了，在这里axis作用于列。    \n现在我们调用mean(1)求均值\ndf.mean(axis=1)&#x27;&#x27;&#x27;out:a    0.742645b    0.438589c    0.503720d    0.472655dtype: float64out end;&#x27;&#x27;&#x27;\n\n对于上面的例子来说，当axis为1时却求出了每一行的均值。  \n\n现在我们来看一下官方帮助的解释：\n\n轴用来为超过一维的数组定义的属性，二维数组拥有两个轴，第0轴沿着行垂直往下。第一轴沿着列的水平方向延申\n用图片来解释就是下图。浅显易懂\n\n注意官方使用纵轴和横轴和来解释0和1，而轴是有方向的。所以不要用行和列的思维去解释行和列。因为行和列是没有方向的有了上面的理解之后，我们就可以解释为什么mean(1)时求出的是每一行的平均值了其实是沿着从左到右的方向（也就是上面我们提到的横轴）求出平均值，并不是我们所误解的每一行求平均值。 作用在drop()上时，也是横向发生变化，体现在列的值减少\n","categories":["python","pandas"],"tags":["python","pandas"]},{"title":"用python实现排序算法","url":"/2019/12/16/%E7%94%A8python%E5%AE%9E%E7%8E%B0%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","content":"\n排序在很多种情况下都会用到，尽管python有自带的sort排序。但是很多时候我们还是要根据实际情况采取最适合的排序方法。这里我们用python来实现8大排序中的5个常见的排序。其余三个以后再更新。\n\n\n\n用Python实现8大排序冒泡排序def maopao_sort(a):    if len(a) == 1:        return a    length = len(a)    for i in range(length):        ischanged = 0        for j in range(length-1):            if a[j] &gt; a[j+1]:                a[j],a[j+1] = a[j+1],a[j]                ischanged = 1        if ischanged==0:            break    return a\n\n选择排序def xuanze_sort(a):    if len(a) == 1:        return a    length = len(a)    for j in range(length):        k = find_min(a[j:])        a[j],a[k+j] = a[k+j],a[j]    return a    def find_min(a):    m = a[0]    k = 0    for i in range(len(a)):        if a[i]&lt;m:            m = a[i]            k = i    return k\n\n插入排序def insert_sort(a):    if len(a) == 1:        return a    length = len(a)    for i in range(1,length):        for j in range(0,i):            if a[j]&gt;a[i]:                m = a[i]                a[j+1:i+1] = a[j:i]                a[j] = m    return a\n\n快速排序def quick_sort(a):    if len(a) == 1:        return a    if len(a) == 0:        return []    m = a[0]    a.pop(0)    left = [i for i in a if i&lt;=m]    right = [i for i in a if i&gt;m]    return quick_sort(left) + [m] + quick_sort(right)\n\n归并排序def merge_sort(a):    if len(a) == 1:        return a    half = int(len(a)/2)    left = merge_sort(a[:half])    right = merge_sort(a[half:])    return merge(left,right)def merge(left,right):    result = []    i = 0    j = 0    while i &lt; len(left) and j &lt; len(right):        if left[i] &lt;= right[j]:            result.append(left[i])            i += 1        else:            result.append(right[j])            j += 1    result.extend(left[i:])    result.extend(right[j:])    return result\n\n","categories":["数据结构","python"],"tags":["python","排序"]},{"title":"rpm查找源码包的基本流程","url":"/2020/08/21/rpm%E6%9F%A5%E6%89%BE%E6%BA%90%E7%A0%81%E5%8C%85%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B/","content":"\nlinux系统修复Bug时通常需要找到rpm源码包进行修改，本文主要介绍如何进行源码包的匹配。\n\n\n\n查找源码包流程第一种方法通过进程名称查找\n先用top找到相关的进程名，可以后面使用-接参数，可灵活使用\ntop\n\n找到对应的进程名称之后通过rpm -qa搜索进程名，可以出现部分rpm包\nrpm -qa | grep 进程名称\n\n可以匹配出几个rpm安装包，使用这种方法可能匹配出来的包较多，所以不能够确定具体时哪个包所以不太确定  \n第二种方法通过汉化包查找\n首先进入到 /usr/share/locale目录\ncd /usr/share/locale\n\n然后再在此目录内匹配搜索相关信息，例如:\ngrep -r &quot;发送到桌面快捷方式&quot;\n\n基本可以确定是哪个文件里面有这个汉化包然后根据上面搜索到的文件路径，使用rpm -qf匹配时哪个安装包\nrpm -qf &quot;/usr/share/locale/上面查找到文件的路径&quot;\n\n确定安装包的名称\n然后根据匹配到的安装包名通过 rpm -qi 找到源码包名字\nrpm -qi 安装包名称\n\n找到源码包之后下载源码包，找到相应的源码修改即可\n可将两种方法结合起来灵活使用为佳\n","categories":["linux"],"tags":["linux","rpm 编包"]},{"title":"numpy average与mean区别","url":"/2019/12/04/numpy%20average%E4%B8%8Emean%E5%8C%BA%E5%88%AB,/","content":"\naverage和mean都表示均值，但是两个函数却是各有侧重点。这就要求我们在特定的情况下调用最适合的函数。这里我们就来讲一下这连个容易混淆的方法。\n\n\n\nnumpy average与mean区别这里看几个小例子\nIn [5]: df = pd.DataFrame(&#123;&#x27;data1&#x27;:np.random.randn(8),&#x27;data2&#x27;:np.random.randn(8)&#125;)In [6]: dfOut[6]:      data1     data20 -0.904163  1.2667691  0.349836  0.3729432 -0.140213 -1.8504333  0.159576 -0.7125054 -0.133263 -0.7103425 -0.426558  2.5693806 -0.478641 -0.9128757 -0.159328  0.988578\n\n在不传入axis的情况下，对df分别进行average()与mean()运算\n\nIn [10]: np.average(df)Out[10]: -0.04507746461893059In [12]: np.mean(df)Out[12]:data1   -0.216594data2    0.126439dtype: float64\n\n可见np.average方法是对整体取平均值，而np.mean()是默认axis=0的情况下求平均值且两个函数返回的数据类型不同，np.average()返回array数组，而np.mean()返回的是Series类型\n在传入axis为0情况下，对df分别进行average()与mean()运算\nIn [11]: np.average(df,0)Out[11]: array([-0.In [13]: np.mean(df,0)In [13]: np.mean(df,0)Out[13]:data1   -0.216594data2    0.126439dtype: float64\n\n可见，两个函数返回数据一样，但类型不一样\n\n在axis等于1的情况下，结果与上例相似，在此不举例\n\n除此之外average还可以计算加权平均值\n什么是加权品均值，这里举个例子\na = [1,2,3,4,5]，b=[2,3,4,5,6]\n以b为权重取a的加权平均值结果就是\n1*2 + 2*3 + 3*4 + 4*5 + 5*6/2 + 3 + 4 + 5 + 6\n所以这里还是举上面的df为例，取以data2为权重data1的加权平均值\nIn [17]: np.average(df[&#x27;data1&#x27;],weights=df[&#x27;data2&#x27;])Out[17]: -1.572923774192011\n\n得出结果\n","categories":["python","numpy"],"tags":["numpy","python","数据分析"]},{"title":"numpy中meshgrid函数","url":"/2019/12/04/numpy%E4%B8%ADmeshgrid%E5%87%BD%E6%95%B0/","content":"numpy中meshgrid函数\n先来看官方文档： https://docs.scipy.org/doc/numpy/reference/generated/numpy.meshgrid.html功能：从一个坐标向量中返回一个坐标矩阵参数：  \n\nx1，x2，x3：一维的数组代表网格的坐标\nindexing：{‘xy’,’ij’}，笛卡尔坐标’xy’或者矩阵’ij’下标作为输出，默认是笛卡尔坐标\nsparse：bool类型，如果是True，返回一个稀疏矩阵保存在内存中，默认为False\ncopy： bool类型，如果是False，返回一个原始数组的视图保存在内存中，默认是True。如果，sparse和copy都为False，将有可能返回一个不连续的数组。而且，如果广播数组的元素超过一个，可以使用一个独立的内存。如果想要对这个数组进行写操作，请先拷贝这个数组。 \n\n看完官方文档之后还是一脸懵逼？？？？直接上例子解释\n\n\nIn [1]: nx,ny = (3,2)In [4]: x = np.linspace(1,2,nx) # [1,1.5,2]In [6]: y = np.linspace(1,2,ny) # [1,2]In [7]: xv,yv = np.meshgrid(x,y)In [10]: xvOut[10]:array([[1. , 1.5, 2. ],       [1. , 1.5, 2. ]])In [11]: yvOut[11]:array([[1., 1., 1.],       [2., 2., 2.]])       \n\n上面的例子可以看出是将两个输入的数组进行拓展，前一个拓展与后一个有关，后一个拓展与前一个有关。前一个是竖轴拓展，后一个是横轴拓展。  \n因为 y 的长度为2，所以 x 竖向被拓展成原来的两倍。同理，y被拓展成横向的三倍 ，输入由原来的数组变成了矩阵，下面我们来看一下表格矩阵的坐标：\nIn [1]: xv.ravel()Out[1]:array([1.,1.5,2.,1.,1.5,2.])In [2]: yv.ravel()Out[2]:array([1., 1., 1., 2., 2., 2.])\n\nravel函数的作用是将矩阵变成一个一维的数组，其中xv.ravel()表示x轴的坐标，yv.ravel()表示y轴的坐标，我们将x轴与y轴的坐标一一对应，就形成了一个网格的坐标  \n如果将sparse参数设置为True，就不会向上面一样拓展了，它产生的网格不是所有的坐标，只有网格对角线上的坐标。  \nIn [1]: xv,yv = np.meshgrid(x,y,sparse=True)In [2]: xvOut[2]:array([[1. , 1.5, 2. ]])In [3]: yvOut[3]:array([[1.],       [2.]])\n\n补充，这里的数组参数也可以是3个，相应的会产生3个矩阵。实践出真知，最好还是实践一下\n","categories":["python","numpy"],"tags":["numpy","python","数据分析"]},{"title":"读书笔记-代码整洁之道（程序员的职业素养）","url":"/2025/12/12/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E4%BB%A3%E7%A0%81%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93-1%EF%BC%88%E4%B8%93%E4%B8%9A%E4%B8%BB%E4%B9%89%EF%BC%89/","content":"\n代码整洁之道（程序员的职业素养）是每个程序员必读的一本书，这本书虽然没有讲关于编码方式（在子妹篇，代码整洁之道里有写）的内容，但是就职业素养，也就是专业的程序员应该如何做事方面，作者结合自己的的工作经历，给出了一些见解，值得我们学习。\n\n\n\n专业主义成为一个优秀的人应该拥有的品质\n\n担当责任\n不行损坏之事\n不破坏软件功能\n不要破坏结构\n\n\n职业道德\n了解自己所处的领域\n坚持学习\n练习\n合作\n辅导\n了解业务领域\n与雇主/客户保持一致\n谦逊\\\n\n\n\n说“不”\n能就是能，不能就是不能，不要说“试试看”\n\n对抗角色面对不合理deadline，不要说，“试试看”，因为上级会讲“试试看”理解成“好的，没问题”。如果上级听到了”试试看”这类的话，也应该进行进一步确认，确认这个“试试看”是不是能够确信能在规定时间内解决问题。\n正确的做法是，达成最佳的可能结果，双方各表异议相互说“不”，然后找到双方都能接受的解决方案。工作中不可能避免任何冲突，完全详细也不见得是好事。\n高风险时刻越是高风险时刻，越要把自己已经的信息和风险暴露出来，然后重新评估预期，当然，作为上级，同样也要在知悉新的预估结果时，向业务方说明情况，而不是拖的更久。\n要有团队精神作为小组长，应该倾听员工的合理要求，比如，员工明确说明，哪些是能做到的，哪些是做不到的，小组长应该和员工站在一起，向上明确说“不”。\n不要说“试试看”“试试看”，意味着承认之前没有竭尽全力，只要在加把劲还是可以达成目标的，因此许诺“尝试”，实际上是在承诺确保成功，压力就需要你来抗了。如果没有达到预期的效果，那么就表示你失败了。所以，在关键时刻，不要说“试试看”。实际上，在这种情况下，领导需要降低自己预期，并且向上反馈风险。\n消极对抗假设员工的预估结果，小组长没有告知上级，而员工仍按照自己的计划推进，那么这就是消极对抗，正确的做法是员工应该直接和上级沟通，来阻止灾难的发生。\n说“是“承诺用语做出承诺，包含三个步骤\n\n口头上说自己会去做\n心里认真对待做出的承诺\n真正付诸行动识别”缺乏承诺“的征兆包含以下几个用词和短语的，会表明”缺乏承诺“，需要注意\n需要/应当\n希望/但愿\n让我们真正的承诺听起来是什么样子的我将在…之前…对自己将会做某件事做了清晰的事实陈述。需要为自己做出的承诺付出责任。但是就算给出承诺，也会有完成不了的时候，可能是依赖别人，也可能是有一些点没有考虑到，也可能是不太确信自己是否真的能完成依赖别人采取行动，和依赖的人进行沟通为考虑周全重新调整别人是你的预期，越快越好不太确定自己是否能完成全力前进，离目标更近，当然也要提前告知风险\n\n做出承诺或许让人听着很害怕，但是如果一直信守承诺，热家会认为你是一个靠谱的人\n不需要对所有请求都回答“是”，不过，应该努力寻找解决问题的方案，尽可能做到有求必应。\n编码这章标题虽然叫编码，但是作者讲的是编码时的心理，精神和情绪。\n\n如果感到疲劳或者心烦意乱，千万不要编码\n编码时候避免进入流态区，因为进入流态区往往会无法顾及全局。\n\n测试驱动开发TDD三大法则\n在编好失败单元测试之前，不要编写任何产品代码。\n只要有一个单元测试失败了，就不要再写测试代码。\n产品代码恰好能让当前失败的单元测试成功通过即可，不要多写。这个循环不断反复，写一些测试代码，写一些产品代码。两套代码同步增长，互为补充。TDD的优势确定性如果测试用力全部通过，就可以确信代码可以交付缺陷注入率TDD可以显著降低缺陷设计如果不写单元测试，有可能出现各个函数耦合在一起，最终无法写单元测试，因此遵循TDD法则，能够驱动开发者做出松耦合的设计。\n\nTDD的局限性遵循TDD法则也不能保证一定能保证带来上述好处，即使先写单元测试，还是有可能写出糟糕的代码。\n验收测试在我们实际的开发过程中，总会遇到这两个问题\n写代码的人总是希望很早就精确最后要交付什么，因为需要对整个系统进行评估，但是，需求总是变化的，所以评估需要基于不那么精确的需求。\n业务方看到真实的运行情况，也可能会改变自己的想法，这种现象叫观察者效应，每次向业务方展示一项功能，业务方就获得了比之前更多的信息，这些信息反过来又影响到他们对整个系统的看法。\n但是如果避免过早精细化，又会导致迟来的模糊性，对最后交付的东西含糊不清\n本章验收测试的定义为业务方与开发方合作编写的测试，其目的在于确定需求已经完成。\n开发方，业务方，测试方对验收测试达成共识，大家都清楚系统的行为是什么样子。\n验收测试应该进行自动化。\n验收测试不是单元测试，单元测试是程序员写给程序员的，是正式的设计文档，描述代码行为。关心单元测试的是程序员。\n验收测试是业务方写给业务方的，是正式的需求文档，描述了业务方认为系统应该如何运行。关系验收测试的是也无妨和程序员。\n测试策略测试并不是写一些单元测试或者验收测试那么简单。编写这些测试可能只是万里长征的第一步。每个专业的开发团队都需要有一套好的测试策略\n单元测试程序员编写，保证代码是正确的\n组件测试组件测试是验收测试的一种，针对系统各个组件编写\n组件测试由QA和业务人员编写，开发人员提供辅助。\n集成测试测试将组件装配成组，测试组件之间是否能够正常通信。\n集成测试是编排性测试，不会测试业务规则，而是主要测试组件装配在一起是否能够正常连接，正常通信。集成测试一般由系统架构师或主设计师来写。\n系统测试系统测试是针对整个集成完毕的系统进行自动化测试，是最终的集成测试，不会直接测试业务规则，而是测试系统是否已经正确组装完毕，以及系统各个组件之间是否能正确交互，同时应该包含吞吐率测试和性能测试\n系统测试一般由系统架构师和技术负责人编写。\n人工探索式测试需要人工介入，这些测试的意图是，探索系统预期以外的行为，需要使用人类的创新能力。\n时间管理工作中高校管理时间\n会议开发者应该清楚会议的高昂成本，同时清楚自己的时间是宝贵的关于会议，有两条真理\n\n会议是必须的\n会议浪费了大量的时间\n\n拒绝会议邀请你参加会议的人不负责管理你的时间，为时间负责的只有你，所以，如果你收到会议邀请，无比确保出席会议可以给自己目前的工作带来切实且显著的成效，否则不必参加\n离席如果发现参加某个会议是浪费时间，应该想个办法礼貌的退出来\n确定议程与目标如果收到会议邀请，无比弄清楚指定的议题是什么，每个议题多长时间，要取得什么成果，如果没有确切的答案，可以礼貌拒绝\n例会到场时依次回答三个问题\n\n我昨天干了什么\n我今天打算干什么\n遇到了什么问题\n\n每个人的回答时间不应该超过20s，所以每个人的发言不应该超过1min。\n迭代计划会议迭代计划会议用来选择下一轮迭代中实现的开发任务，在会议召开之前必须完成两项任务：评估可选择任务的开发时间，确定这些任务的业务价值。会议节奏应该足够快，简明扼要讨论各个候选任务，决定选择还是放弃，在每个任务上花的时间应该限制在5-10分钟，如果需要更详细的讨论，则应当另选时间，挑出团队中的一部分人专门进行。\n迭代回顾和DEMO展示在迭代末尾召开，团队成员讨论什么做得对，什么做的不对，业务方可以看到最新成果的demo。只会牵涉到最近一两周的工作。\n争论/反对凡事不能在5分钟内解决的争论，都不能靠辩论解决，需要用数据说话。如果争论必须解决，应当要求争论各方在5分钟内向大家摆明问题，然后大家投票。\n注意力点数每个人都有固定点数的注意力，注意力集中的时候会消耗注意力点数，不集中的时候则会恢复。\n如果保持良好的注意力点数\n\n睡眠\n咖啡因\n恢复\n肌肉注意力（可以提升心智注意力）\n输入与输出（接触其他人的创造性思维）\n\n时间拆分和番茄工作法把时间分为番茄时间和非番茄时间，番茄时间是有生产率的，可以真正做点事情，非番茄时间可以处理一些非工作适宜，例如，休息，参加会议等。\n如果工作中陷入死胡同或者泥潭，应该及时发现和修正。\n预估作者给出了预估的几种方法\nPERT\nO: 乐观估计，如果一切进行顺利，可以在这个时间点完成\nN：标称估计，这是概率最大的完成时间点\nP: 悲观估计，这是最糟糕的数字\n\n有了以上三个预估，我们可以像下面这样描述概率分布u = (O + 4N + P) / 6u是任务的期望完成时间\na = (P - O) / 6a是这个任务概率分布的标准差，用来衡量不确定性，如果这个数字很大，就表示非常不确定假设O=1, N=3, P=12,则u = 4.2, a = 1.8那么任务的预估天数是(4.2, 1.8),有可能会5天完成，也可能6天甚至9天。\n如果同时有多个任务，那么总的期望完成时间就是这些任务的期望完成时间的综合假如有三项任务，预估分别是（4.2，1.8），（3.5，22），（6.5， 1.3）\n那么这三项任务的期望完成时间是14天4.2 + 3.5 + 6.5 = 14.2\n总的标准差就是各个任务的标准差平方之和的平方根，也就是√（1.8^ + 2.2^ + 1.3^） ～ 3.13\n所以，任务大概需要14天完成，也可能需要17天（1a）,也可能是2a(20)天，也可能更长时间，，不过概率很小。\n预估任务德尔菲法一群人集合起来，讨论某项任务，预估完成时间，然后重复 ”讨论-预估“\n\n亮手指（同时亮手指，来）\n规划扑克（可以对纸牌设置合理的点数，可以是斐波那契数列，或者其他点数。）\n关联估计（一群人对任务卡片排序，觉得需要时间长的放在右边，短的在左边，任何人都能随意更换卡片顺序，然后拿更换顺序次数最多的拿出来讨论）\n\n大数定律将大任务拆分成小任务，分开预估再汇总。\n压力避免压力承诺避免对没有把握达成的最后期限做出承诺，如果有人代我们做出承诺，出于责任感，我们必须主动找到方法来兑现承诺，但是一定不要接受这些承诺\n保持整洁让系统，代码和设计尽可能整洁，可以避免压力，不要容忍混乱，混乱会降低速。\n危机中的纪律选择那些在危机时刻依然会遵守的纪律原则（如果在危机时刻就不遵守了，就代表你不相信这些原则），比如TDD，保持代码整洁，结对工作…\n如果你遵守的纪律原则是工作的最佳方式，那么即使在危机时刻，也要坚决秉持这些纪律原则\n应对压力\n不要惊慌（努力找到最好的结果）\n沟通（让你所在的团队和领导知道你所处的困境，寻求帮助和指引）\n依靠纪律原则\n寻求帮助（结对编程）\n\n协作本章将的内容主要是作者分享了一些经历，然后讲出自己的一些想法\n\n代码归属团体不要设置代码壁垒，不要阻止别人修改你的代码，而是尽可能多的相互合作，通过合作来达到学习的目的\n\n结对结对工作可以分享知识，通过相互结对来学习系统的不同部分和业务，尽管每位成员都有自己的位置，但是在紧要关头，每位成员也要能接替别人的位置。结对是复查代码最好的方式，系统中不应该包含未经其他程序员复查过的代码，最有效最简单的代码复查方法，就是以互相协作的方式完成代码编写。\n\n\n如果我们真想众生能以变成度日，那么一定要学会交流。\n团队与项目这是章节讲述的是团队和项目哪个优先，是组建一只有凝聚力的团队，把项目分配给团队，还是根据不同的项目，拉起不同团队更优，最后的结论是，团队比项目更难构建，组件一支稳健的团队，让团队在一个又一个项目中整体移动共同工作是较好的做法。\n辅导、学徒期与技艺很多刚毕业的大学生完全无法满足工作中的需要，因此需要有技艺的人进行辅导。在这个章节中，作者以自己的两段经历开头，引出自己没有接受过常规辅导，没有一位老师对他建立起正确的价值观和反思内省的习惯，导致他失去了工作，意在指出辅导的重要性。\n随后指出软件专业人士如何将刚毕业的年轻人提升到专业水准上，应该由实习生-熟练工-大师，循序渐进。\n技艺技艺可通过“模仿”来复制\n技艺包含价值观、原则、技术、态度和正见。\n技艺如何获取，技艺由口口相传和手手相承而来，需要由自身人士向年轻学徒殷勤传授，然后在学徒间相互传播。\n技艺只要可以被人观察到，它就具有传染性。\n如果想传授技艺，首先自己要成为表率，首先自己要成为能工巧匠，展示自己的技艺，然后，将剩余事情交给技艺模因的自然之道。\n","categories":["读书笔记"],"tags":["代码整洁之道"]}]